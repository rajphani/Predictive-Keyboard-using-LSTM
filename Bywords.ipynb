{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Bywords.ipynb","version":"0.3.2","provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"metadata":{"id":"PVqQstu4RR1n","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"55985013-48b6-4dd7-c757-384a19201d25","executionInfo":{"status":"ok","timestamp":1554984046025,"user_tz":-330,"elapsed":3737,"user":{"displayName":"Phaniraj Rallabandi","photoUrl":"https://lh3.googleusercontent.com/-3waliHg4XvU/AAAAAAAAAAI/AAAAAAAAA8g/3GJUn64Wb00/s64/photo.jpg","userId":"06780650722492889436"}}},"cell_type":"code","source":["import numpy as np\n","np.random.seed(42)\n","import tensorflow as tf\n","tf.set_random_seed(42)\n","\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense, Dropout, LSTM\n","from tensorflow.keras.optimizers import RMSprop  \n","\n","from keras.models import Sequential, load_model\n","from keras.layers import Dense, Activation\n","from keras.layers import LSTM, Dropout\n","from keras.layers import TimeDistributed\n","from keras.layers.core import Dense, Activation, Dropout, RepeatVector\n","from keras.optimizers import RMSprop\n","\n","\n","import matplotlib.pyplot as plt\n","import pickle\n","import sys\n","import heapq\n","import seaborn as sns\n","from pylab import rcParams\n","\n","%matplotlib inline\n","\n","sns.set(style='whitegrid', palette='muted', font_scale=1.5)\n","\n","rcParams['figure.figsize'] = 12, 5"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"}]},{"metadata":{"id":"rqRjMMPSRVjE","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"a07e06e2-4bbb-45b5-b915-99a72b3be529","executionInfo":{"status":"ok","timestamp":1554984121173,"user_tz":-330,"elapsed":1521,"user":{"displayName":"Phaniraj Rallabandi","photoUrl":"https://lh3.googleusercontent.com/-3waliHg4XvU/AAAAAAAAAAI/AAAAAAAAA8g/3GJUn64Wb00/s64/photo.jpg","userId":"06780650722492889436"}}},"cell_type":"code","source":["path = 'databook.txt' ## We will use Friedrich Nietzscheâ€™s Beyond Good and Evil as a training corpus for our model.\n","text = open(path).read().lower()\n","print('corpus length:', len(text))"],"execution_count":2,"outputs":[{"output_type":"stream","text":["corpus length: 600894\n"],"name":"stdout"}]},{"metadata":{"id":"G_BxESyMSD6h","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"9de6285c-65a8-4e0f-ba1b-9f0f413dd3f5","executionInfo":{"status":"ok","timestamp":1554984316521,"user_tz":-330,"elapsed":1523,"user":{"displayName":"Phaniraj Rallabandi","photoUrl":"https://lh3.googleusercontent.com/-3waliHg4XvU/AAAAAAAAAAI/AAAAAAAAA8g/3GJUn64Wb00/s64/photo.jpg","userId":"06780650722492889436"}}},"cell_type":"code","source":["list_str = text.split()\n","words = sorted(set(list_str) ## list of distinct words in the corpus\n","\n","word_indices = dict((c, i) for i, c in enumerate(chars)) ## char to index maps\n","indices_word = dict((i, c) for i, c in enumerate(chars)) ## index to char maps\n","\n","print(f'unique chars: {len(chars)}')"],"execution_count":5,"outputs":[{"output_type":"stream","text":["unique chars: 99111\n"],"name":"stdout"}]},{"metadata":{"id":"yJwDDGhad1up","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"a5a18cef-b820-49ae-bac3-e5f541045318","executionInfo":{"status":"ok","timestamp":1554987611452,"user_tz":-330,"elapsed":2108,"user":{"displayName":"Phaniraj Rallabandi","photoUrl":"https://lh3.googleusercontent.com/-3waliHg4XvU/AAAAAAAAAAI/AAAAAAAAA8g/3GJUn64Wb00/s64/photo.jpg","userId":"06780650722492889436"}}},"cell_type":"code","source":["SEQUENCE_LENGTH = 10\n","step = 1\n","sentences = []\n","next_words = []\n","for i in range(0, len(list_str) - SEQUENCE_LENGTH):\n","    sentences.append(list_str[i: i + SEQUENCE_LENGTH])\n","    next_words.append(list_str[i + SEQUENCE_LENGTH])\n","print(f'num training examples: {len(sentences)}')"],"execution_count":10,"outputs":[{"output_type":"stream","text":["num training examples: 99101\n"],"name":"stdout"}]},{"metadata":{"id":"wRA2azy9en6A","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":364},"outputId":"361731a5-9323-4c7b-dada-680a307132f4","executionInfo":{"status":"ok","timestamp":1554987616467,"user_tz":-330,"elapsed":1590,"user":{"displayName":"Phaniraj Rallabandi","photoUrl":"https://lh3.googleusercontent.com/-3waliHg4XvU/AAAAAAAAAAI/AAAAAAAAA8g/3GJUn64Wb00/s64/photo.jpg","userId":"06780650722492889436"}}},"cell_type":"code","source":["for i in range(0,5):\n","  print(sentences[i])\n","  print('--'*20)\n","  print(next_words[i])\n","  print('='*30)"],"execution_count":11,"outputs":[{"output_type":"stream","text":["['preface', 'supposing', 'that', 'truth', 'is', 'a', 'woman--what', 'then?', 'is', 'there']\n","----------------------------------------\n","not\n","==============================\n","['supposing', 'that', 'truth', 'is', 'a', 'woman--what', 'then?', 'is', 'there', 'not']\n","----------------------------------------\n","ground\n","==============================\n","['that', 'truth', 'is', 'a', 'woman--what', 'then?', 'is', 'there', 'not', 'ground']\n","----------------------------------------\n","for\n","==============================\n","['truth', 'is', 'a', 'woman--what', 'then?', 'is', 'there', 'not', 'ground', 'for']\n","----------------------------------------\n","suspecting\n","==============================\n","['is', 'a', 'woman--what', 'then?', 'is', 'there', 'not', 'ground', 'for', 'suspecting']\n","----------------------------------------\n","that\n","==============================\n"],"name":"stdout"}]},{"metadata":{"id":"tEaMRxnIe4Lr","colab_type":"code","colab":{}},"cell_type":"code","source":["X = np.zeros((len(sentences), SEQUENCE_LENGTH, len(chars)), dtype=np.bool) ## 99101 X 10 X 57 arrays of zeros\n","y = np.zeros((len(sentences), len(chars)), dtype=np.bool) ## 200285 X 57 arrays of zeros\n","for i, sentence in enumerate(sentences):  ## All the 200285 are indexed\n","    for t, char in enumerate(sentence): ## In every sentence, each character is indexed\n","        X[i, t, char_indices[char]] = 1  ## every char in each sentence is marked as 1---- 3D one hot vector\n","    y[i, char_indices[next_chars[i]]] = 1 ## in very sentence next char to come is marked as 1---- 2D one hot vector"],"execution_count":0,"outputs":[]}]}